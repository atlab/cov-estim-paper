\subsection*{The sample covariance matrix}
We aim to estimate the true covariance matrix $\Sigma = \E{(x-\mu)(x-\mu)^\T}$ of the instantaneous activity vector $x$ of a population of $p$ neurons. Here $\E{\cdot}$ denotes expectation \TODO{for the true data generating process} and $x$ is the $p\times 1$ vector of real-valued instantaneous firing rates discretized into bins of duration $\Delta t$ and $\mu = \E{x}$.  

For more rigorous notation, definitions, and derivations, see Appendix. 

The usual estimator of $\Sigma$ is the sample covariance matrix
\begin{equation}
\hat \Sigma_0 = \frac 1 \nu \sum\limits_{t=1}^n (x(t)-\mu)(x(t)-\mu)^\T 
\end{equation}
where $x(t),\;t=1,\ldots,n$ are sequential observations of population activity inferred from calcium signals; $\nu$ is the number of degrees of freedom. For independent observations $\nu=n-1$ because estimation of the mean $\mu$ accounts for one degree of freedom. When observations are correlated, as is the case with calcium signals, $\nu < n-1$ and may be estimated from the signal. 

The sample covariance matrix is constructed to be unbiased, such that $\E{\hat\Sigma_0} = \Sigma$. 

\subsection*{Evaluation of covariance matrix estimators}
The quality of a covariance matrix estimate $\hat\Sigma$ is measured by a real-valued \emph{loss function} $\loss{\hat\Sigma,\Sigma}$.  The loss function quantifies the deviation of $\hat\Sigma$ from $\Sigma$ and attains its minimum  when $\hat\Sigma = \Sigma$. 

For the purposes of this study, we adopted the \emph{negative normal log-likelihood loss} function:
\begin{equation}\label{eq:loss}
\loss{\hat\Sigma,\Sigma} = \frac 1 p\left[\ln \det \hat \Sigma + \Tr(\hat \Sigma^{-1}\Sigma)\right]
\end{equation}
This choice is motivated by mathematical convenience. Other popular choices for the loss function are the Frobenius norm of the difference $\hat\Sigma-\Sigma$, Stein's entropy loss, and quadratic loss \cite{James:1961,Ledoit:2004,Schafer:2005,Fan:2008}.  We expect that the main conclusions of our study will not change qualitatively under other well behaved loss functions.

The aim of our project is to produce covariance matrix estimates that minimize the expected loss 
\begin{equation}
r = \E{\loss{\hat\Sigma, \Sigma}}
\end{equation}
which is know as the \emph{risk} of $\hat\Sigma$.

In practice, the true value $\Sigma$ is not accessible and estimators' risks must be estimated from the data.  This may be accomplished through \emph{validation}. 
Let $\hat\Sigma_0^\prime$ denote a sample covariance matrix measured from an independent sample that was not used included in the computation of $\hat\Sigma$. 

$\loss{\cdot,\cdot}$ is additive in its second argument such that
 \begin{equation}\label{eq:additivity}
 \loss{\hat\Sigma,X_1} + \loss{\hat\Sigma,X_2} \equiv \loss{\hat\Sigma,X_1+X_2}
 \end{equation}
Then \emph{validation loss}  \TODO{check appropriate term}
\begin{equation}\label{eq:validationLoss}
\hat \ell = \loss{\hat\Sigma,\hat\Sigma_0^\prime}
\end{equation}
is an unbiased estimate of the risk:
 \begin{equation}\label{eq:empiricalRisk}
\E[(\hat\Sigma, \hat\Sigma_0^\prime)] {\hat\ell} 
= \E[(\hat\Sigma, \hat\Sigma_0^\prime)]{\loss{\hat\Sigma,\hat\Sigma_0^\prime}}
= \E{\loss{\hat\Sigma,\E{\hat\Sigma_0^\prime}}}
= \E{\loss{\hat\Sigma,\Sigma}} = r
 \end{equation}
Therefore, estimators resulting in consistently lower validation loss can be inferred to produce estimates that are closer to truth than estimators with higher validation loss.

Other popular loss functions such as entropy loss do not comply with Eq.~\ref{eq:additivity} and their validation loss is not an unbiased estimate of risk.

Since $\loss{\cdot,\cdot}$ is equivalent to negative normal log likelihood, the above derivation has led to the familiar criterion that the optimal covariance matrix estimator is one that consistently maximizes cross-validated normal log likelihood.